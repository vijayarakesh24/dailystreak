import { createRequire as __createRequire } from 'node:module';
import { fileURLToPath as __fileURLToPath } from 'node:url';
import { dirname as __dirname_ } from 'node:path';
const require = __createRequire(import.meta.url);
const __filename = __fileURLToPath(import.meta.url);
const __dirname = __dirname_(__filename);
import {
  OUTPUT_DIR,
  importBuilders,
  require_dist as require_dist3,
  staticFiles,
  validateConfig,
  writeBuildResult
} from "../../chunks/chunk-TUJE7TAQ.js";
import {
  require_semver
} from "../../chunks/chunk-FS6YY47L.js";
import {
  pullCommandLogic
} from "../../chunks/chunk-X3FFQHYP.js";
import {
  pickOverrides,
  readProjectSettings
} from "../../chunks/chunk-4LIW5I5B.js";
import {
  require_dist
} from "../../chunks/chunk-PFKNXAIG.js";
import "../../chunks/chunk-7OCX2CUX.js";
import "../../chunks/chunk-B2VOZEQL.js";
import "../../chunks/chunk-HEYUAUQE.js";
import {
  buildCommand
} from "../../chunks/chunk-M5TNZBCT.js";
import "../../chunks/chunk-I3CS55DR.js";
import "../../chunks/chunk-RPXSHEGV.js";
import {
  readJSONFile
} from "../../chunks/chunk-7AN5BKPP.js";
import {
  DEFAULT_VERCEL_CONFIG_FILENAME,
  compileVercelConfig,
  findSourceVercelConfigFile,
  require_main
} from "../../chunks/chunk-I4USAAOX.js";
import {
  help
} from "../../chunks/chunk-YO3WHMKT.js";
import {
  CantParseJSONFile,
  TelemetryClient,
  VERCEL_DIR,
  cmd,
  getCommandName,
  getFlagsSpecification,
  getProjectLink,
  packageName,
  parseArguments,
  parseTarget,
  printError,
  require_dist2,
  require_frameworks,
  require_lib,
  require_lib2,
  require_minimatch2 as require_minimatch,
  stamp_default,
  toEnumerableError
} from "../../chunks/chunk-62EDLXXJ.js";
import {
  emoji,
  init_pkg,
  output_manager_default,
  pkg_default,
  prependEmoji
} from "../../chunks/chunk-6TPHDHH6.js";
import {
  require_source
} from "../../chunks/chunk-6H7E5JAU.js";
import {
  __toESM
} from "../../chunks/chunk-LCYENQ63.js";

// src/commands/build/index.ts
var import_chalk = __toESM(require_source(), 1);
var import_dotenv = __toESM(require_main(), 1);
var import_fs_extra2 = __toESM(require_lib(), 1);
var import_minimatch = __toESM(require_minimatch(), 1);
var import_semver = __toESM(require_semver(), 1);
var import_client = __toESM(require_dist(), 1);
var import_frameworks2 = __toESM(require_frameworks(), 1);
var import_fs_detectors2 = __toESM(require_dist2(), 1);
var import_routing_utils = __toESM(require_dist3(), 1);
import { join as join2, normalize, relative as relative2, resolve, sep } from "path";
import {
  download,
  FileFsRef,
  getDiscontinuedNodeVersions,
  getInstalledPackageVersion,
  getServiceUrlEnvVars,
  normalizePath,
  NowBuildError as NowBuildError2,
  runNpmInstall,
  runCustomInstallCommand,
  resetCustomInstallCommandSet,
  Span,
  validateNpmrc,
  isBackendBuilder
} from "@vercel/build-utils";

// src/util/build/corepack.ts
var import_fs_extra = __toESM(require_lib(), 1);
import { delimiter, join } from "path";
import { spawnAsync } from "@vercel/build-utils";
async function initCorepack({
  repoRootPath
}) {
  if (process.env.ENABLE_EXPERIMENTAL_COREPACK !== "1") {
    return null;
  }
  const pkg = await readJSONFile(
    join(repoRootPath, "package.json")
  );
  if (pkg instanceof CantParseJSONFile) {
    output_manager_default.warn(
      "Warning: Could not enable corepack because package.json is invalid JSON",
      pkg.meta.parseErrorLocation
    );
  } else if (!pkg?.packageManager) {
    output_manager_default.warn(
      'Warning: Could not enable corepack because package.json is missing "packageManager" property'
    );
  } else {
    output_manager_default.log(
      `Detected ENABLE_EXPERIMENTAL_COREPACK=1 and "${pkg.packageManager}" in package.json`
    );
    const corepackRootDir = join(repoRootPath, VERCEL_DIR, "cache", "corepack");
    const corepackHomeDir = join(corepackRootDir, "home");
    const corepackShimDir = join(corepackRootDir, "shim");
    await import_fs_extra.default.mkdirp(corepackHomeDir);
    await import_fs_extra.default.mkdirp(corepackShimDir);
    process.env.COREPACK_HOME = corepackHomeDir;
    process.env.PATH = `${corepackShimDir}${delimiter}${process.env.PATH}`;
    const pkgManagerName = pkg.packageManager.split("@")[0];
    await spawnAsync(
      "corepack",
      ["enable", pkgManagerName, "--install-directory", corepackShimDir],
      {
        prettyCommand: `corepack enable ${pkgManagerName}`
      }
    );
    return corepackShimDir;
  }
  return null;
}
function cleanupCorepack(corepackShimDir) {
  if (process.env.COREPACK_HOME) {
    delete process.env.COREPACK_HOME;
  }
  if (process.env.PATH) {
    process.env.PATH = process.env.PATH.replace(
      `${corepackShimDir}${delimiter}`,
      ""
    );
  }
}

// src/util/build/monorepo.ts
var import_fs_detectors = __toESM(require_dist2(), 1);
var import_title = __toESM(require_lib2(), 1);
import { relative, basename } from "path";
import { debug } from "@vercel/build-utils";
async function setMonorepoDefaultSettings(cwd, workPath, projectSettings) {
  const localFileSystem = new import_fs_detectors.LocalFileSystemDetector(cwd);
  const projectName = basename(workPath);
  const relativeToRoot = relative(workPath, cwd);
  const setCommand = (command, value) => {
    if (projectSettings[command]) {
      debug(
        `Skipping auto-assignment of ${command} as it is already set via project settings or configuration overrides.`
      );
    } else {
      projectSettings[command] = value;
    }
  };
  try {
    const result = await (0, import_fs_detectors.getMonorepoDefaultSettings)(
      projectName,
      relative(cwd, workPath),
      relativeToRoot,
      localFileSystem
    );
    if (result === null) {
      return;
    }
    projectSettings.monorepoManager = result.monorepoManager;
    const { monorepoManager, ...commands } = result;
    output_manager_default.log(
      `Detected ${(0, import_title.default)(monorepoManager)}. Adjusting default settings...`
    );
    if (commands.buildCommand) {
      setCommand("buildCommand", commands.buildCommand);
    }
    if (commands.installCommand) {
      setCommand("installCommand", commands.installCommand);
    }
    if (commands.commandForIgnoringBuildStep) {
      setCommand(
        "commandForIgnoringBuildStep",
        commands.commandForIgnoringBuildStep
      );
    }
  } catch (error) {
    if (error instanceof import_fs_detectors.MissingBuildPipeline || error instanceof import_fs_detectors.MissingBuildTarget) {
      output_manager_default.warn(`${error.message} Skipping automatic setting assignment.`);
      return;
    }
    throw error;
  }
}

// src/util/build/scrub-argv.ts
function scrubArgv(argv) {
  const clonedArgv = [...argv];
  const tokenRE = /^(-[A-Za-z]*[bet]|--(?:build-env|env|token))(=.*)?$/;
  for (let i = 0, len = clonedArgv.length; i < len; i++) {
    const m = clonedArgv[i].match(tokenRE);
    if (m?.[2]) {
      clonedArgv[i] = `${m[1]}=REDACTED`;
    } else if (m && i + 1 < len) {
      clonedArgv[++i] = "REDACTED";
    }
  }
  return clonedArgv;
}

// src/util/build/service-route-ownership.ts
function isWebServiceWithPrefix(service) {
  return service.type === "web" && typeof service.routePrefix === "string";
}
function normalizeRoutePrefix(routePrefix) {
  let normalized = routePrefix.startsWith("/") ? routePrefix : `/${routePrefix}`;
  if (normalized !== "/" && normalized.endsWith("/")) {
    normalized = normalized.slice(0, -1);
  }
  return normalized || "/";
}
function escapeForRegex(value) {
  return value.replace(/[|\\{}()[\]^$+*?.]/g, "\\$&");
}
function toPrefixMatcher(routePrefix) {
  return `${escapeForRegex(routePrefix)}(?:/|$)`;
}
function isDescendantPrefix(candidate, prefix) {
  return candidate !== prefix && candidate.startsWith(`${prefix}/`);
}
function getWebRoutePrefixes(services) {
  const unique = /* @__PURE__ */ new Set();
  for (const service of services) {
    if (!isWebServiceWithPrefix(service))
      continue;
    unique.add(normalizeRoutePrefix(service.routePrefix));
  }
  return Array.from(unique);
}
function getOwnershipGuard(ownerPrefix, allWebPrefixes) {
  const owner = normalizeRoutePrefix(ownerPrefix);
  const nonRootPrefixes = allWebPrefixes.filter((prefix) => prefix !== "/").sort((a, b) => b.length - a.length);
  if (owner === "/") {
    return nonRootPrefixes.map((prefix) => `(?!${toPrefixMatcher(prefix)})`).join("");
  }
  const descendants = nonRootPrefixes.filter(
    (prefix) => isDescendantPrefix(prefix, owner)
  );
  const positive = `(?=${toPrefixMatcher(owner)})`;
  const negative = descendants.map((prefix) => `(?!${toPrefixMatcher(prefix)})`).join("");
  return `${positive}${negative}`;
}
function scopeRouteSourceToOwnership(source, ownershipGuard) {
  if (!ownershipGuard)
    return source;
  const inner = source.startsWith("^") ? source.slice(1) : source;
  return `^${ownershipGuard}(?:${inner})`;
}
function scopeRoutesToServiceOwnership({
  routes,
  owner,
  allServices
}) {
  if (!isWebServiceWithPrefix(owner)) {
    return routes;
  }
  const allWebPrefixes = getWebRoutePrefixes(allServices);
  const ownershipGuard = getOwnershipGuard(owner.routePrefix, allWebPrefixes);
  if (!ownershipGuard) {
    return routes;
  }
  return routes.map((route) => {
    if ("handle" in route || typeof route.src !== "string") {
      return route;
    }
    return {
      ...route,
      src: scopeRouteSourceToOwnership(route.src, ownershipGuard)
    };
  });
}

// src/util/build/sort-builders.ts
var import_frameworks = __toESM(require_frameworks(), 1);
function sortBuilders(builds) {
  const frontendRuntimeSet = new Set(
    import_frameworks.frameworkList.map((f) => f.useRuntime?.use || "@vercel/static-build")
  );
  frontendRuntimeSet.delete("@vercel/python");
  frontendRuntimeSet.delete("@vercel/ruby");
  frontendRuntimeSet.delete("@vercel/rust");
  const toNumber = (build) => build.use === "@vercel/python" || build.use === "@vercel/ruby" || build.use === "@vercel/rust" ? 1 : frontendRuntimeSet.has(build.use) ? 0 : 2;
  return builds.sort((build1, build2) => {
    return toNumber(build1) - toNumber(build2);
  });
}

// src/commands/build/index.ts
init_pkg();

// src/util/telemetry/commands/build/index.ts
var BuildTelemetryClient = class extends TelemetryClient {
  trackCliOptionOutput(path) {
    if (path) {
      this.trackCliOption({
        option: "output",
        value: this.redactedValue
      });
    }
  }
  trackCliOptionTarget(option) {
    if (option) {
      this.trackCliOption({
        option: "target",
        value: this.redactedTargetName(option)
      });
    }
  }
  trackCliFlagProd(flag) {
    if (flag) {
      this.trackCliFlag("prod");
    }
  }
  trackCliFlagYes(flag) {
    if (flag) {
      this.trackCliFlag("yes");
    }
  }
  trackCliFlagStandalone(flag) {
    if (flag) {
      this.trackCliFlag("standalone");
    }
  }
};

// src/util/validate-cron-secret.ts
import { NowBuildError } from "@vercel/build-utils";
function validateCronSecret(cronSecret) {
  if (!cronSecret) {
    return null;
  }
  if (cronSecret !== cronSecret.trim()) {
    return new NowBuildError({
      code: "INVALID_CRON_SECRET",
      message: "The `CRON_SECRET` environment variable contains leading or trailing whitespace, which is not allowed in HTTP header values.",
      link: "https://vercel.link/securing-cron-jobs",
      action: "Learn More"
    });
  }
  const invalidChars = [];
  for (let i = 0; i < cronSecret.length; i++) {
    const code = cronSecret.charCodeAt(i);
    const isValidChar = code === 9 || // HTAB
    code >= 32 && code <= 126;
    if (!isValidChar) {
      invalidChars.push({
        char: cronSecret[i],
        index: i,
        code
      });
    }
  }
  if (invalidChars.length > 0) {
    const descriptions = invalidChars.slice(0, 3).map(({ code, index }) => {
      if (code < 32) {
        return `control character (0x${code.toString(16).padStart(2, "0")}) at position ${index}`;
      } else if (code === 127) {
        return `DEL character at position ${index}`;
      } else {
        return `non-ASCII character (0x${code.toString(16).padStart(2, "0")}) at position ${index}`;
      }
    });
    const moreCount = invalidChars.length - 3;
    const moreText = moreCount > 0 ? `, and ${moreCount} more` : "";
    return new NowBuildError({
      code: "INVALID_CRON_SECRET",
      message: `The \`CRON_SECRET\` environment variable contains characters that are not valid in HTTP headers: ${descriptions.join(", ")}${moreText}. Only visible ASCII characters (letters, digits, symbols), spaces, and tabs are allowed.`,
      link: "https://vercel.link/securing-cron-jobs",
      action: "Learn More"
    });
  }
  return null;
}

// src/commands/build/index.ts
import { mkdir, writeFile } from "fs/promises";
var InMemoryReporter = class {
  constructor() {
    this.events = [];
  }
  report(event) {
    this.events.push(event);
  }
};
async function main(client) {
  const telemetryClient = new BuildTelemetryClient({
    opts: {
      store: client.telemetryEventStore
    }
  });
  const reporter = new InMemoryReporter();
  const rootSpan = new Span({ name: "vc", reporter });
  let { cwd } = client;
  if (process.env.__VERCEL_BUILD_RUNNING) {
    output_manager_default.error(
      `${cmd(
        `${packageName} build`
      )} must not recursively invoke itself. Check the Build Command in the Project Settings or the ${cmd(
        "build"
      )} script in ${cmd("package.json")}`
    );
    output_manager_default.error(
      `Learn More: https://vercel.link/recursive-invocation-of-commands`
    );
    return 1;
  } else {
    process.env.__VERCEL_BUILD_RUNNING = "1";
  }
  let parsedArgs = null;
  const flagsSpecification = getFlagsSpecification(buildCommand.options);
  try {
    parsedArgs = parseArguments(client.argv.slice(2), flagsSpecification);
    telemetryClient.trackCliOptionOutput(parsedArgs.flags["--output"]);
    telemetryClient.trackCliOptionTarget(parsedArgs.flags["--target"]);
    telemetryClient.trackCliFlagProd(parsedArgs.flags["--prod"]);
    telemetryClient.trackCliFlagYes(parsedArgs.flags["--yes"]);
    telemetryClient.trackCliFlagStandalone(parsedArgs.flags["--standalone"]);
  } catch (error) {
    printError(error);
    return 1;
  }
  if (parsedArgs.flags["--help"]) {
    telemetryClient.trackCliFlagHelp("build");
    output_manager_default.print(help(buildCommand, { columns: client.stderr.columns }));
    return 2;
  }
  const target = parseTarget({
    flagName: "target",
    flags: parsedArgs.flags
  }) || "preview";
  const yes = Boolean(parsedArgs.flags["--yes"]);
  const hasDeprecatedEnvVar = process.env.VERCEL_EXPERIMENTAL_STANDALONE_BUILD === "1";
  if (hasDeprecatedEnvVar) {
    output_manager_default.warn(
      "The VERCEL_EXPERIMENTAL_STANDALONE_BUILD environment variable is deprecated. Please use the --standalone flag instead."
    );
  }
  const standalone = Boolean(
    parsedArgs.flags["--standalone"] || hasDeprecatedEnvVar
  );
  try {
    await validateNpmrc(cwd);
  } catch (err) {
    output_manager_default.prettyError(err);
    return 1;
  }
  const link = await getProjectLink(client, cwd);
  const projectRootDirectory = link?.projectRootDirectory ?? "";
  if (link?.repoRoot) {
    cwd = client.cwd = link.repoRoot;
  }
  const vercelDir = join2(cwd, projectRootDirectory, VERCEL_DIR);
  let project = await readProjectSettings(vercelDir);
  const isTTY = process.stdin.isTTY;
  while (!project?.settings) {
    let confirmed = yes;
    if (!confirmed) {
      if (!isTTY) {
        output_manager_default.print(
          `No Project Settings found locally. Run ${getCommandName(
            "pull --yes"
          )} to retrieve them.`
        );
        return 1;
      }
      confirmed = await client.input.confirm(
        `No Project Settings found locally. Run ${getCommandName(
          "pull"
        )} for retrieving them?`,
        true
      );
    }
    if (!confirmed) {
      output_manager_default.print(`Canceled. No Project Settings retrieved.
`);
      return 0;
    }
    const { argv: originalArgv } = client;
    client.cwd = join2(cwd, projectRootDirectory);
    client.argv = [
      ...originalArgv.slice(0, 2),
      "pull",
      `--environment`,
      target
    ];
    const result = await pullCommandLogic(
      client,
      client.cwd,
      Boolean(parsedArgs.flags["--yes"]),
      target,
      parsedArgs.flags
    );
    if (result !== 0) {
      return result;
    }
    client.cwd = cwd;
    client.argv = originalArgv;
    project = await readProjectSettings(vercelDir);
  }
  const defaultOutputDir = join2(cwd, projectRootDirectory, OUTPUT_DIR);
  const outputDir = parsedArgs.flags["--output"] ? resolve(parsedArgs.flags["--output"]) : defaultOutputDir;
  await Promise.all([
    import_fs_extra2.default.remove(outputDir),
    // Also delete `.vercel/output`, in case the script is targeting Build Output API directly
    outputDir !== defaultOutputDir ? import_fs_extra2.default.remove(defaultOutputDir) : void 0
  ]);
  const buildsJson = {
    "//": "This file was generated by the `vercel build` command. It is not part of the Build Output API.",
    target,
    argv: scrubArgv(process.argv)
  };
  if (!process.env.VERCEL_BUILD_IMAGE) {
    output_manager_default.warn(
      "Build not running on Vercel. System environment variables will not be available."
    );
  }
  const envToUnset = /* @__PURE__ */ new Set(["VERCEL", "NOW_BUILDER"]);
  try {
    const envPath = join2(
      cwd,
      projectRootDirectory,
      VERCEL_DIR,
      `.env.${target}.local`
    );
    const dotenvResult = import_dotenv.default.config({
      path: envPath,
      debug: output_manager_default.isDebugEnabled()
    });
    if (dotenvResult.error) {
      output_manager_default.debug(
        `Failed loading environment variables: ${dotenvResult.error}`
      );
    } else if (dotenvResult.parsed) {
      for (const key of Object.keys(dotenvResult.parsed)) {
        envToUnset.add(key);
      }
      output_manager_default.debug(`Loaded environment variables from "${envPath}"`);
    }
    if (project.settings.analyticsId) {
      envToUnset.add("VERCEL_ANALYTICS_ID");
      process.env.VERCEL_ANALYTICS_ID = project.settings.analyticsId;
    }
    process.env.VERCEL = "1";
    process.env.NOW_BUILDER = "1";
    try {
      await rootSpan.child("vc.doBuild").trace(
        (span) => doBuild(client, project, buildsJson, cwd, outputDir, span, standalone)
      );
    } finally {
      await rootSpan.stop();
    }
    return 0;
  } catch (err) {
    output_manager_default.prettyError(err);
    buildsJson.error = toEnumerableError(err);
    const buildsJsonPath = join2(outputDir, "builds.json");
    const configJsonPath = join2(outputDir, "config.json");
    await import_fs_extra2.default.outputJSON(buildsJsonPath, buildsJson, {
      spaces: 2
    });
    await import_fs_extra2.default.writeJSON(configJsonPath, { version: 3 }, { spaces: 2 });
    return 1;
  } finally {
    try {
      const diagnosticsOutputPath = join2(outputDir, "diagnostics");
      await mkdir(diagnosticsOutputPath, { recursive: true });
      await writeFile(
        join2(diagnosticsOutputPath, "cli_traces.json"),
        JSON.stringify(reporter.events)
      );
    } catch (err) {
      output_manager_default.error("Failed to write diagnostics trace file");
      output_manager_default.prettyError(err);
    }
    for (const key of envToUnset) {
      delete process.env[key];
    }
    delete process.env.VERCEL_INSTALL_COMPLETED;
    resetCustomInstallCommandSet();
  }
}
async function doBuild(client, project, buildsJson, cwd, outputDir, span, standalone = false) {
  const { localConfigPath } = client;
  const VALID_DEPLOYMENT_ID_PATTERN = /^[a-zA-Z0-9_-]+$/;
  const workPath = join2(cwd, project.settings.rootDirectory || ".");
  const sourceConfigFile = await findSourceVercelConfigFile(workPath);
  let corepackShimDir;
  if (sourceConfigFile) {
    corepackShimDir = await initCorepack({ repoRootPath: cwd });
    const installCommand = project.settings.installCommand;
    if (typeof installCommand === "string") {
      if (installCommand.trim()) {
        output_manager_default.log(`Running install command before config compilation...`);
        await runCustomInstallCommand({
          destPath: workPath,
          installCommand,
          spawnOpts: { env: process.env },
          projectCreatedAt: project.settings.createdAt
        });
      } else {
        output_manager_default.debug("Skipping empty install command");
      }
    } else {
      output_manager_default.log(`Installing dependencies before config compilation...`);
      await runNpmInstall(
        workPath,
        [],
        { env: process.env },
        void 0,
        project.settings.createdAt
      );
    }
    process.env.VERCEL_INSTALL_COMPLETED = "1";
  }
  const compileResult = await compileVercelConfig(workPath);
  const vercelConfigPath = localConfigPath || compileResult.configPath || join2(workPath, "vercel.json");
  const [pkg, vercelConfig, nowConfig, hasInstrumentation] = await Promise.all([
    readJSONFile(join2(workPath, "package.json")),
    readJSONFile(vercelConfigPath),
    readJSONFile(join2(workPath, "now.json")),
    (0, import_fs_detectors2.detectInstrumentation)(new import_fs_detectors2.LocalFileSystemDetector(workPath))
  ]);
  if (pkg instanceof CantParseJSONFile)
    throw pkg;
  if (vercelConfig instanceof CantParseJSONFile)
    throw vercelConfig;
  if (nowConfig instanceof CantParseJSONFile)
    throw nowConfig;
  if (hasInstrumentation) {
    output_manager_default.debug(
      "OpenTelemetry instrumentation detected. Automatic fetch instrumentation will be disabled."
    );
    process.env.VERCEL_TRACING_DISABLE_AUTOMATIC_FETCH_INSTRUMENTATION = "1";
  }
  if (vercelConfig) {
    vercelConfig[import_client.fileNameSymbol] = compileResult.wasCompiled ? compileResult.sourceFile || DEFAULT_VERCEL_CONFIG_FILENAME : "vercel.json";
  } else if (nowConfig) {
    nowConfig[import_client.fileNameSymbol] = "now.json";
  }
  const localConfig = vercelConfig || nowConfig || {};
  const validateError = validateConfig(localConfig);
  if (validateError) {
    throw validateError;
  }
  if (localConfig.crons && localConfig.crons.length > 0) {
    const cronSecretError = validateCronSecret(process.env.CRON_SECRET);
    if (cronSecretError) {
      throw cronSecretError;
    }
  }
  const projectSettings = {
    ...project.settings,
    ...pickOverrides(localConfig)
  };
  if (process.env.VERCEL_BUILD_MONOREPO_SUPPORT === "1" && pkg?.scripts?.["vercel-build"] === void 0 && projectSettings.rootDirectory !== null && projectSettings.rootDirectory !== ".") {
    await setMonorepoDefaultSettings(cwd, workPath, projectSettings);
  }
  if (process.env.VERCEL_EXPERIMENTAL_EMBED_FLAG_DEFINITIONS === "1") {
    const { emitFlagsDefinitions } = await import("../../chunks/emit-flags-definitions-FVPV6R5V.js");
    await emitFlagsDefinitions(cwd, process.env);
  }
  const files = (await staticFiles(workPath, {})).map(
    (f) => normalizePath(relative2(workPath, f))
  );
  const routesResult = (0, import_routing_utils.getTransformedRoutes)(localConfig);
  if (routesResult.error) {
    throw routesResult.error;
  }
  if (localConfig.builds && localConfig.functions) {
    throw new NowBuildError2({
      code: "bad_request",
      message: "The `functions` property cannot be used in conjunction with the `builds` property. Please remove one of them.",
      link: "https://vercel.link/functions-and-builds"
    });
  }
  let builds = localConfig.builds || [];
  let zeroConfigRoutes = [];
  let detectedServices;
  let isZeroConfig = false;
  if (builds.length > 0) {
    output_manager_default.warn(
      "Due to `builds` existing in your configuration file, the Build and Development Settings defined in your Project Settings will not apply. Learn More: https://vercel.link/unused-build-settings"
    );
    builds = builds.map((b) => expandBuild(files, b)).flat();
  } else {
    isZeroConfig = true;
    const detectedBuilders = await (0, import_fs_detectors2.detectBuilders)(files, pkg, {
      ...localConfig,
      projectSettings,
      ignoreBuildScript: true,
      featHandleMiss: true,
      workPath
    });
    if (detectedBuilders.errors && detectedBuilders.errors.length > 0) {
      throw detectedBuilders.errors[0];
    }
    for (const w of detectedBuilders.warnings) {
      output_manager_default.warn(w.message, null, w.link, w.action || "Learn More");
    }
    if (detectedBuilders.builders) {
      builds = detectedBuilders.builders;
    } else {
      builds = [{ src: "**", use: "@vercel/static" }];
    }
    detectedServices = detectedBuilders.services;
    if (detectedServices && detectedServices.length > 0) {
      const serviceUrlEnvVars = getServiceUrlEnvVars({
        services: detectedServices,
        frameworkList: import_frameworks2.frameworkList,
        currentEnv: process.env,
        deploymentUrl: process.env.VERCEL_URL
      });
      for (const [key, value] of Object.entries(serviceUrlEnvVars)) {
        process.env[key] = value;
        output_manager_default.debug(`Injected service URL env var: ${key}=${value}`);
      }
    }
    zeroConfigRoutes.push(...detectedBuilders.redirectRoutes || []);
    zeroConfigRoutes.push(
      ...(0, import_routing_utils.appendRoutesToPhase)({
        routes: [],
        newRoutes: detectedBuilders.rewriteRoutes,
        phase: "filesystem"
      })
    );
    zeroConfigRoutes = (0, import_routing_utils.appendRoutesToPhase)({
      routes: zeroConfigRoutes,
      newRoutes: detectedBuilders.errorRoutes,
      phase: "error"
    });
    zeroConfigRoutes.push(...detectedBuilders.defaultRoutes || []);
  }
  const builderSpecs = new Set(builds.map((b) => b.use));
  const buildersWithPkgs = await importBuilders(builderSpecs, cwd);
  const filesMap = {};
  for (const path of files) {
    const fsPath = join2(workPath, path);
    const { mode } = await import_fs_extra2.default.stat(fsPath);
    filesMap[path] = new FileFsRef({ mode, fsPath });
  }
  const buildStamp = stamp_default();
  await import_fs_extra2.default.mkdirp(outputDir);
  const ops = [];
  const buildsJsonBuilds = new Map(
    builds.map((build) => {
      const builderWithPkg = buildersWithPkgs.get(build.use);
      if (!builderWithPkg) {
        throw new Error(`Failed to load Builder "${build.use}"`);
      }
      const { builder, pkg: builderPkg } = builderWithPkg;
      return [
        build,
        {
          require: builderPkg.name,
          requirePath: builderWithPkg.path,
          apiVersion: builder.version,
          ...build
        }
      ];
    })
  );
  buildsJson.builds = Array.from(buildsJsonBuilds.values());
  await writeBuildJson(buildsJson, outputDir);
  const meta = {
    skipDownload: true,
    cliVersion: pkg_default.version
  };
  const sortedBuilders = sortBuilders(builds);
  const buildResults = /* @__PURE__ */ new Map();
  const overrides = [];
  const repoRootPath = cwd;
  if (!corepackShimDir) {
    corepackShimDir = await initCorepack({ repoRootPath });
  }
  const diagnostics = {};
  const hasDetectedServices = detectedServices !== void 0 && detectedServices.length > 0;
  const servicesByBuilderSrc = /* @__PURE__ */ new Map();
  if (hasDetectedServices) {
    for (const service of detectedServices) {
      if (service.builder.src) {
        const existing = servicesByBuilderSrc.get(service.builder.src);
        if (existing) {
          throw new NowBuildError2({
            code: "DUPLICATE_SERVICE_BUILDER_SRC",
            message: `Services "${existing.name}" and "${service.name}" both have the same builder source "${service.builder.src}". Each service must have a unique builder source.`
          });
        }
        servicesByBuilderSrc.set(service.builder.src, service);
      }
    }
  }
  for (const build of sortedBuilders) {
    if (typeof build.src !== "string")
      continue;
    const builderWithPkg = buildersWithPkgs.get(build.use);
    if (!builderWithPkg) {
      throw new Error(`Failed to load Builder "${build.use}"`);
    }
    try {
      const { builder, pkg: builderPkg } = builderWithPkg;
      const service = hasDetectedServices ? servicesByBuilderSrc.get(build.src) : void 0;
      let buildWorkPath = workPath;
      let buildEntrypoint = build.src;
      let buildFiles = filesMap;
      if (service && service.workspace !== ".") {
        const wsPrefix = service.workspace + "/";
        buildWorkPath = join2(workPath, service.workspace);
        buildEntrypoint = build.src.startsWith(wsPrefix) ? build.src.slice(wsPrefix.length) : build.src;
        buildFiles = {};
        for (const [filePath, file] of Object.entries(filesMap)) {
          if (filePath.startsWith(wsPrefix)) {
            buildFiles[filePath.slice(wsPrefix.length)] = file;
          }
        }
        output_manager_default.debug(
          `Service "${service.name}": workspace-rooted build at "${buildWorkPath}", entrypoint "${buildEntrypoint}" (original: "${build.src}")`
        );
      }
      const settingsForEnv = service ? {
        buildCommand: service.buildCommand ?? void 0,
        installCommand: service.installCommand ?? void 0,
        outputDirectory: projectSettings.outputDirectory ?? void 0,
        nodeVersion: projectSettings.nodeVersion ?? void 0
      } : projectSettings;
      for (const key of [
        "buildCommand",
        "installCommand",
        "outputDirectory",
        "nodeVersion"
      ]) {
        const value = settingsForEnv[key];
        const envKey = `VERCEL_PROJECT_SETTINGS_` + key.replace(/[A-Z]/g, (letter) => `_${letter}`).toUpperCase();
        if (typeof value === "string") {
          process.env[envKey] = value;
          output_manager_default.debug(`Setting env ${envKey} to "${value}"`);
        } else {
          delete process.env[envKey];
        }
      }
      const isFrontendBuilder = build.config && "framework" in build.config;
      const builderFramework = build.config?.framework ?? projectSettings.framework;
      let buildConfig;
      if (isZeroConfig) {
        if (service) {
          buildConfig = {
            ...build.config,
            // Override project-level settings with service-specific ones.
            // The project-level framework is "services" which must NOT be
            // propagated to individual builders.
            projectSettings: {
              ...projectSettings,
              framework: service.framework ?? null,
              buildCommand: service.buildCommand ?? null,
              installCommand: service.installCommand ?? null
            },
            installCommand: service.installCommand ?? void 0,
            buildCommand: service.buildCommand ?? void 0,
            framework: builderFramework,
            nodeVersion: projectSettings.nodeVersion,
            bunVersion: localConfig.bunVersion ?? void 0
          };
        } else {
          buildConfig = {
            outputDirectory: projectSettings.outputDirectory ?? void 0,
            ...build.config,
            projectSettings,
            installCommand: projectSettings.installCommand ?? void 0,
            devCommand: projectSettings.devCommand ?? void 0,
            buildCommand: projectSettings.buildCommand ?? void 0,
            framework: projectSettings.framework,
            nodeVersion: projectSettings.nodeVersion,
            bunVersion: localConfig.bunVersion ?? void 0
          };
        }
      } else {
        buildConfig = {
          ...build.config || {},
          bunVersion: localConfig.bunVersion ?? void 0
        };
      }
      const builderSpan = span.child("vc.builder", {
        name: builderPkg.name
      });
      const serviceRoutePrefix = build.config?.routePrefix;
      const serviceWorkspace = build.config?.workspace;
      const buildOptions = {
        files: buildFiles,
        entrypoint: buildEntrypoint,
        workPath: buildWorkPath,
        repoRootPath,
        config: buildConfig,
        meta,
        span: builderSpan,
        ...typeof serviceRoutePrefix === "string" || typeof serviceWorkspace === "string" ? {
          service: {
            routePrefix: typeof serviceRoutePrefix === "string" ? serviceRoutePrefix : void 0,
            workspace: typeof serviceWorkspace === "string" ? serviceWorkspace : void 0
          }
        } : void 0
      };
      output_manager_default.debug(
        `Building entrypoint "${build.src}" with "${builderPkg.name}"`
      );
      let buildResult;
      try {
        buildResult = await builderSpan.trace(
          async () => builder.build(buildOptions)
        );
        if (!hasDetectedServices && buildConfig.zeroConfig && isFrontendBuilder && "output" in buildResult && !buildResult.routes) {
          const framework2 = import_frameworks2.frameworkList.find(
            (f) => f.slug === buildConfig.framework
          );
          if (framework2) {
            const defaultRoutes = await getFrameworkRoutes(
              framework2,
              buildWorkPath
            );
            buildResult.routes = defaultRoutes;
          }
        }
      } finally {
        try {
          const builderDiagnostics = await builderSpan.child("vc.builder.diagnostics").trace(async () => {
            return await builder.diagnostics?.(buildOptions);
          });
          Object.assign(diagnostics, builderDiagnostics);
        } catch (error) {
          output_manager_default.error("Collecting diagnostics failed");
          output_manager_default.debug(error);
        }
      }
      if (buildResult && "output" in buildResult && "runtime" in buildResult.output && "type" in buildResult.output && buildResult.output.type === "Lambda") {
        const lambdaRuntime = buildResult.output.runtime;
        if (getDiscontinuedNodeVersions().some((o) => o.runtime === lambdaRuntime)) {
          throw new NowBuildError2({
            code: "NODEJS_DISCONTINUED_VERSION",
            message: `The Runtime "${build.use}" is using "${lambdaRuntime}", which is discontinued. Please upgrade your Runtime to a more recent version or consult the author for more details.`,
            link: "https://vercel.link/function-runtimes"
          });
        }
      }
      if ("output" in buildResult && buildResult.output && (isBackendBuilder(build) || build.use === "@vercel/python")) {
        const routesJsonPath = join2(buildWorkPath, ".vercel", "routes.json");
        if ((0, import_fs_extra2.existsSync)(routesJsonPath)) {
          try {
            const routesJson = await readJSONFile(routesJsonPath);
            if (routesJson && typeof routesJson === "object" && "routes" in routesJson && Array.isArray(routesJson.routes)) {
              const indexLambda = "index" in buildResult.output ? buildResult.output["index"] : void 0;
              const convertedRoutes = [];
              const convertedOutputs = indexLambda ? { index: indexLambda } : {};
              for (const route of routesJson.routes) {
                if (typeof route.source !== "string") {
                  continue;
                }
                const { src } = (0, import_routing_utils.sourceToRegex)(route.source);
                const newRoute = {
                  src,
                  dest: route.source
                };
                if (route.methods) {
                  newRoute.methods = route.methods;
                }
                if (route.source === "/") {
                  continue;
                }
                if (indexLambda) {
                  convertedOutputs[route.source] = indexLambda;
                }
                convertedRoutes.push(newRoute);
              }
              buildResult.routes = [
                { handle: "filesystem" },
                ...convertedRoutes,
                { src: "/(.*)", dest: "/" }
              ];
              if (indexLambda) {
                buildResult.output = convertedOutputs;
              }
            }
          } catch (error) {
            output_manager_default.error(`Failed to read routes.json: ${error}`);
          }
        }
      }
      if (hasDetectedServices && service && (0, import_fs_detectors2.isRouteOwningBuilder)(service) && "routes" in buildResult && Array.isArray(buildResult.routes) && detectedServices) {
        buildResult.routes = scopeRoutesToServiceOwnership({
          routes: buildResult.routes,
          owner: service,
          allServices: detectedServices
        });
      }
      buildResults.set(build, buildResult);
      let buildOutputLength = 0;
      if ("output" in buildResult) {
        buildOutputLength = Array.isArray(buildResult.output) ? buildResult.output.length : 1;
      }
      ops.push(
        builderSpan.child("vc.builder.writeBuildResult", {
          buildOutputLength: String(buildOutputLength)
        }).trace(
          () => writeBuildResult({
            repoRootPath,
            outputDir,
            buildResult,
            build,
            builder,
            builderPkg,
            vercelConfig: localConfig,
            standalone,
            workPath: buildWorkPath
          })
        ).then(
          (override) => {
            if (override)
              overrides.push(override);
          },
          (err) => err
        )
      );
    } catch (err) {
      const buildJsonBuild = buildsJsonBuilds.get(build);
      if (buildJsonBuild) {
        buildJsonBuild.error = toEnumerableError(err);
      }
      throw err;
    } finally {
      ops.push(
        download(diagnostics, join2(outputDir, "diagnostics")).then(
          () => void 0,
          (err) => err
        )
      );
    }
  }
  if (corepackShimDir) {
    cleanupCorepack(corepackShimDir);
  }
  const errors = await Promise.all(ops);
  for (const error of errors) {
    if (error) {
      throw error;
    }
  }
  let needBuildsJsonOverride = false;
  const speedInsightsVersion = await getInstalledPackageVersion(
    "@vercel/speed-insights"
  );
  if (speedInsightsVersion) {
    buildsJson.features = {
      ...buildsJson.features ?? {},
      speedInsightsVersion
    };
    needBuildsJsonOverride = true;
  }
  const webAnalyticsVersion = await getInstalledPackageVersion("@vercel/analytics");
  if (webAnalyticsVersion) {
    buildsJson.features = {
      ...buildsJson.features ?? {},
      webAnalyticsVersion
    };
    needBuildsJsonOverride = true;
  }
  if (needBuildsJsonOverride) {
    await writeBuildJson(buildsJson, outputDir);
  }
  const configPath = join2(outputDir, "config.json");
  const existingConfig = await readJSONFile(configPath);
  if (existingConfig instanceof CantParseJSONFile) {
    throw existingConfig;
  }
  if (existingConfig) {
    if ("deploymentId" in existingConfig && typeof existingConfig.deploymentId === "string") {
      const deploymentId = existingConfig.deploymentId;
      if (deploymentId.length > 32) {
        throw new NowBuildError2({
          code: "INVALID_DEPLOYMENT_ID",
          message: `The deploymentId "${deploymentId}" must be 32 characters or less. Please choose a shorter deploymentId in your config.`,
          link: "https://vercel.com/docs/skew-protection#custom-skew-protection-deployment-id"
        });
      }
      if (!VALID_DEPLOYMENT_ID_PATTERN.test(deploymentId)) {
        throw new NowBuildError2({
          code: "INVALID_DEPLOYMENT_ID",
          message: `The deploymentId "${deploymentId}" contains invalid characters. Only alphanumeric characters (a-z, A-Z, 0-9), hyphens (-), and underscores (_) are allowed.`,
          link: "https://vercel.com/docs/skew-protection#custom-skew-protection-deployment-id"
        });
      }
    }
    if (existingConfig.overrides) {
      overrides.push(existingConfig.overrides);
    }
    for (const [build, buildResult] of buildResults.entries()) {
      if ("buildOutputPath" in buildResult) {
        output_manager_default.debug(`Using "config.json" for "${build.use}`);
        buildResults.set(build, existingConfig);
        break;
      }
    }
  }
  const builderRoutes = Array.from(
    buildResults.entries()
  ).filter((b) => "routes" in b[1] && Array.isArray(b[1].routes)).map((b) => {
    const build = b[0];
    const buildResult = b[1];
    let entrypoint = build.src;
    if (hasDetectedServices && typeof build.src === "string") {
      const service = servicesByBuilderSrc.get(build.src);
      if (service && service.type === "web" && typeof service.routePrefix === "string") {
        entrypoint = getServicesMergeEntrypoint(service, build.src);
      }
    }
    return {
      use: build.use,
      entrypoint,
      routes: buildResult.routes
    };
  });
  if (zeroConfigRoutes.length) {
    builderRoutes.unshift({
      use: "@vercel/zero-config-routes",
      entrypoint: "/",
      routes: zeroConfigRoutes
    });
  }
  const mergedRoutes = (0, import_routing_utils.mergeRoutes)({
    userRoutes: routesResult.routes,
    builds: builderRoutes
  });
  const mergedImages = mergeImages(localConfig.images, buildResults.values());
  const mergedCrons = mergeCrons(localConfig.crons, buildResults.values());
  const mergedWildcard = mergeWildcard(buildResults.values());
  const mergedDeploymentId = await mergeDeploymentId(
    existingConfig?.deploymentId,
    buildResults.values(),
    workPath
  );
  if (mergedDeploymentId) {
    if (mergedDeploymentId.length > 32) {
      throw new NowBuildError2({
        code: "INVALID_DEPLOYMENT_ID",
        message: `The deploymentId "${mergedDeploymentId}" must be 32 characters or less. Please choose a shorter deploymentId in your config.`,
        link: "https://vercel.com/docs/skew-protection#custom-skew-protection-deployment-id"
      });
    }
    if (!VALID_DEPLOYMENT_ID_PATTERN.test(mergedDeploymentId)) {
      throw new NowBuildError2({
        code: "INVALID_DEPLOYMENT_ID",
        message: `The deploymentId "${mergedDeploymentId}" contains invalid characters. Only alphanumeric characters (a-z, A-Z, 0-9), hyphens (-), and underscores (_) are allowed.`,
        link: "https://vercel.com/docs/skew-protection#custom-skew-protection-deployment-id"
      });
    }
  }
  const mergedOverrides = overrides.length > 0 ? Object.assign({}, ...overrides) : void 0;
  const framework = await getFramework(workPath, buildResults);
  const config = {
    version: 3,
    routes: mergedRoutes,
    images: mergedImages,
    wildcard: mergedWildcard,
    overrides: mergedOverrides,
    framework,
    crons: mergedCrons,
    ...detectedServices && detectedServices.length > 0 && { services: detectedServices },
    ...mergedDeploymentId && { deploymentId: mergedDeploymentId }
  };
  await import_fs_extra2.default.writeJSON(join2(outputDir, "config.json"), config, { spaces: 2 });
  await writeFlagsJSON(buildResults.values(), outputDir);
  const relOutputDir = relative2(cwd, outputDir);
  output_manager_default.print(
    `${prependEmoji(
      `Build Completed in ${import_chalk.default.bold(
        relOutputDir.startsWith("..") ? outputDir : relOutputDir
      )} ${import_chalk.default.gray(buildStamp())}`,
      emoji("success")
    )}
`
  );
}
async function getFramework(cwd, buildResults) {
  const detectedFramework = await (0, import_fs_detectors2.detectFrameworkRecord)({
    fs: new import_fs_detectors2.LocalFileSystemDetector(cwd),
    frameworkList: import_frameworks2.frameworkList
  });
  if (!detectedFramework) {
    return;
  }
  if (detectedFramework.useRuntime) {
    for (const [build, buildResult] of buildResults.entries()) {
      if ("framework" in buildResult && build.use === detectedFramework.useRuntime.use) {
        return buildResult.framework;
      }
    }
  }
  if (detectedFramework.detectedVersion) {
    if (import_semver.default.valid(detectedFramework.detectedVersion)) {
      return {
        version: detectedFramework.detectedVersion
      };
    }
  }
  const frameworkVersion = (0, import_fs_detectors2.detectFrameworkVersion)(detectedFramework);
  if (frameworkVersion) {
    return {
      version: frameworkVersion
    };
  }
}
function expandBuild(files, build) {
  if (!build.use) {
    throw new NowBuildError2({
      code: `invalid_build_specification`,
      message: "Field `use` is missing in build specification",
      link: "https://vercel.com/docs/concepts/projects/project-configuration#builds",
      action: "View Documentation"
    });
  }
  let src = normalize(build.src || "**").split(sep).join("/");
  if (src === "." || src === "./") {
    throw new NowBuildError2({
      code: `invalid_build_specification`,
      message: "A build `src` path resolves to an empty string",
      link: "https://vercel.com/docs/concepts/projects/project-configuration#builds",
      action: "View Documentation"
    });
  }
  if (src[0] === "/") {
    src = src.substring(1);
  }
  const matches = files.filter(
    (name) => name === src || (0, import_minimatch.default)(name, src, { dot: true })
  );
  return matches.map((m) => {
    return {
      ...build,
      src: m
    };
  });
}
function mergeImages(images, buildResults) {
  for (const result of buildResults) {
    if ("images" in result && result.images) {
      images = Object.assign({}, images, result.images);
    }
  }
  return images;
}
function mergeCrons(crons = [], buildResults) {
  for (const result of buildResults) {
    if ("crons" in result && result.crons) {
      crons = crons.concat(result.crons);
    }
  }
  return crons;
}
function mergeWildcard(buildResults) {
  let wildcard = void 0;
  for (const result of buildResults) {
    if ("wildcard" in result && result.wildcard) {
      if (!wildcard)
        wildcard = [];
      wildcard.push(...result.wildcard);
    }
  }
  return wildcard;
}
async function mergeDeploymentId(existingDeploymentId, buildResults, workPath) {
  if (existingDeploymentId) {
    return existingDeploymentId;
  }
  for (const result of buildResults) {
    if ("deploymentId" in result && result.deploymentId) {
      return result.deploymentId;
    }
  }
  try {
    const routesManifestPath = join2(workPath, ".next", "routes-manifest.json");
    if (await import_fs_extra2.default.pathExists(routesManifestPath)) {
      const routesManifest = await readJSONFile(
        routesManifestPath
      );
      if (routesManifest && !(routesManifest instanceof CantParseJSONFile)) {
        if (routesManifest.deploymentId) {
          return routesManifest.deploymentId;
        }
      }
    }
  } catch {
  }
  return void 0;
}
async function writeFlagsJSON(buildResults, outputDir) {
  const flagsFilePath = join2(outputDir, "flags.json");
  let hasFlags = true;
  const flags = await import_fs_extra2.default.readJSON(flagsFilePath).catch((error) => {
    if (error.code === "ENOENT") {
      hasFlags = false;
      return { definitions: {} };
    }
    throw error;
  });
  for (const result of buildResults) {
    if (!("flags" in result) || !result.flags || !result.flags.definitions)
      continue;
    for (const [key, definition] of Object.entries(result.flags.definitions)) {
      if (result.flags.definitions[key]) {
        output_manager_default.warn(
          `The flag "${key}" was found multiple times. Only its first occurrence will be considered.`
        );
        continue;
      }
      hasFlags = true;
      flags.definitions[key] = definition;
    }
  }
  if (hasFlags) {
    await import_fs_extra2.default.writeJSON(flagsFilePath, flags, { spaces: 2 });
  }
}
async function writeBuildJson(buildsJson, outputDir) {
  await import_fs_extra2.default.writeJSON(join2(outputDir, "builds.json"), buildsJson, { spaces: 2 });
}
async function getFrameworkRoutes(framework, dirPrefix) {
  let routes = [];
  if (typeof framework.defaultRoutes === "function") {
    routes = await framework.defaultRoutes(dirPrefix);
  } else if (Array.isArray(framework.defaultRoutes)) {
    routes = framework.defaultRoutes;
  }
  return routes;
}
function normalizeServiceRoutePrefix(routePrefix) {
  let prefix = routePrefix.startsWith("/") ? routePrefix : `/${routePrefix}`;
  if (prefix !== "/" && prefix.endsWith("/")) {
    prefix = prefix.slice(0, -1);
  }
  return prefix;
}
function getServicesMergeEntrypoint(service, buildSrc) {
  const routePrefix = typeof service.routePrefix === "string" ? service.routePrefix : "/";
  const normalized = normalizeServiceRoutePrefix(routePrefix);
  const sortKey = String(1e4 - normalized.length).padStart(5, "0");
  return `svc:${sortKey}:${normalized}:${service.name}:${buildSrc}`;
}
export {
  main as default
};

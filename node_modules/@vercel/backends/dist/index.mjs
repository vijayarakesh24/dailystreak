import { builtinModules, createRequire } from "node:module";
import { delimiter, dirname, extname, join } from "path";
import { FileBlob, FileFsRef, NodejsLambda, Span, debug, defaultCachePathGlob, download, execCommand, getEnvForPackageManager, getNodeBinPaths, getNodeVersion, glob, isBackendFramework, isBunVersion, isExperimentalBackendsWithoutIntrospectionEnabled, runNpmInstall, runPackageJsonScript, scanParentDirs } from "@vercel/build-utils";
import { createWriteStream, existsSync, mkdirSync, mkdtempSync, readFileSync, rmSync, unlinkSync, writeFileSync } from "node:fs";
import { lstat, readFile, rm, stat } from "node:fs/promises";
import { dirname as dirname$1, extname as extname$1, isAbsolute, join as join$1, relative } from "node:path";
import { build as build$2 } from "rolldown";
import { exports } from "resolve.exports";
import { isNativeError } from "node:util/types";
import { nodeFileTrace as nodeFileTrace$1, resolve } from "@vercel/nft";
import { transform } from "oxc-transform";
import { createRequire as createRequire$1 } from "module";
import { spawn } from "child_process";
import { existsSync as existsSync$1 } from "fs";
import execa from "execa";
import { readFile as readFile$1, writeFile } from "fs/promises";
import { spawn as spawn$1 } from "node:child_process";
import { tmpdir } from "node:os";
import { z } from "zod";

//#region src/utils.ts
async function downloadInstallAndBundle(args) {
	const { entrypoint, files, workPath, meta, config, repoRootPath } = args;
	await download(files, workPath, meta);
	const entrypointFsDirname = join(workPath, dirname(entrypoint));
	const { cliType, lockfileVersion, packageJsonPackageManager, turboSupportsCorepackHome } = await scanParentDirs(entrypointFsDirname, true, repoRootPath);
	const spawnEnv = getEnvForPackageManager({
		cliType,
		lockfileVersion,
		packageJsonPackageManager,
		env: process.env,
		turboSupportsCorepackHome,
		projectCreatedAt: config.projectSettings?.createdAt
	});
	const installCommand = config.projectSettings?.installCommand;
	if (typeof installCommand === "string") if (installCommand.trim()) {
		console.log(`Running "install" command: \`${installCommand}\`...`);
		await execCommand(installCommand, {
			env: spawnEnv,
			cwd: entrypointFsDirname
		});
	} else console.log(`Skipping "install" command...`);
	else await runNpmInstall(entrypointFsDirname, [], { env: spawnEnv }, meta, config.projectSettings?.createdAt);
	return {
		entrypointFsDirname,
		spawnEnv
	};
}
async function maybeExecBuildCommand(args, { spawnEnv, entrypointFsDirname }) {
	const projectBuildCommand = args.config.projectSettings?.buildCommand;
	if (projectBuildCommand) {
		const nodeBinPath = getNodeBinPaths({
			base: args.repoRootPath || args.workPath,
			start: args.workPath
		}).join(delimiter);
		return execCommand(projectBuildCommand, {
			env: {
				...spawnEnv,
				PATH: `${nodeBinPath}${delimiter}${spawnEnv?.PATH || process.env.PATH}`
			},
			cwd: args.workPath
		});
	}
	return runPackageJsonScript(entrypointFsDirname, ["build"], { env: spawnEnv }, args.config.projectSettings?.createdAt);
}

//#endregion
//#region src/cervel/plugin.ts
const CJS_SHIM_PREFIX$1 = "\0cjs-shim:";
const plugin = (args) => {
	const packageJsonCache = /* @__PURE__ */ new Map();
	const shimMeta = /* @__PURE__ */ new Map();
	const { tracedPaths } = args.context;
	const isBareImport = (id) => {
		return !id.startsWith(".") && !id.startsWith("/") && !/^[a-z][a-z0-9+.-]*:/i.test(id);
	};
	/**
	* Read and cache package.json contents
	*/
	const getPackageJson = async (pkgPath) => {
		if (packageJsonCache.has(pkgPath)) return packageJsonCache.get(pkgPath);
		try {
			const contents = await readFile(pkgPath, "utf-8");
			const parsed = JSON.parse(contents);
			packageJsonCache.set(pkgPath, parsed);
			return parsed;
		} catch {
			packageJsonCache.set(pkgPath, null);
			return null;
		}
	};
	/**
	* Determine if a resolved module is CommonJS based on package.json exports
	*/
	const isCommonJS = async (bareImport, resolvedPath, resolvedInfo) => {
		const ext = extname$1(resolvedPath);
		if (ext === ".cjs") return true;
		if (ext === ".mjs") return false;
		if (ext === ".js" || ext === ".ts") {
			const pkgJsonPath = resolvedInfo.packageJsonPath;
			if (!pkgJsonPath) return true;
			const pkgJson = await getPackageJson(pkgJsonPath);
			if (!pkgJson) return true;
			const pkgDir = dirname$1(pkgJsonPath);
			const relativePath = resolvedPath.startsWith(pkgDir) ? resolvedPath.slice(pkgDir.length + 1).replace(/\\/g, "/") : null;
			if (!relativePath) return pkgJson.type !== "module";
			const pkgName = pkgJson.name || "";
			const subpath = bareImport.startsWith(pkgName) ? `.${bareImport.slice(pkgName.length)}` || "." : ".";
			try {
				if (exports(pkgJson, subpath, {
					require: false,
					conditions: ["node", "import"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return false;
				if (exports(pkgJson, subpath, {
					require: true,
					conditions: ["node", "require"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return true;
			} catch (err) {
				console.warn("Export resolution failed::", err);
			}
			if (pkgJson.module) return false;
			return pkgJson.type !== "module";
		}
		return true;
	};
	const isLocalImport = (id) => {
		if (id.startsWith("node:")) return false;
		if (id.includes("node_modules")) return false;
		return true;
	};
	return {
		name: "cervel",
		resolveId: {
			order: "pre",
			async handler(id, importer, rOpts) {
				if (id.startsWith(CJS_SHIM_PREFIX$1)) return {
					id,
					external: false
				};
				const resolved = await this.resolve(id, importer, rOpts);
				if (builtinModules.includes(id)) return {
					id: `node:${id}`,
					external: true
				};
				if (resolved?.id && isLocalImport(resolved.id)) tracedPaths.add(resolved.id);
				if (importer?.startsWith(CJS_SHIM_PREFIX$1) && isBareImport(id)) return {
					id,
					external: true
				};
				if (importer && isBareImport(id) && resolved?.id?.includes("node_modules")) {
					if (args.shimBareImports) {
						if (await isCommonJS(id, resolved.id, resolved)) {
							const importerPkgJsonPath = (await this.resolve(importer))?.packageJsonPath;
							if (importerPkgJsonPath) {
								const importerPkgDir = relative(args.repoRootPath, dirname$1(importerPkgJsonPath));
								const shimId$1 = `${CJS_SHIM_PREFIX$1}${importerPkgDir.replace(/\//g, "_")}_${id.replace(/\//g, "_")}`;
								shimMeta.set(shimId$1, {
									pkgDir: importerPkgDir,
									pkgName: id
								});
								return {
									id: shimId$1,
									external: false
								};
							}
							const shimId = `${CJS_SHIM_PREFIX$1}${id.replace(/\//g, "_")}`;
							shimMeta.set(shimId, {
								pkgDir: "",
								pkgName: id
							});
							return {
								id: shimId,
								external: false
							};
						}
					}
					return {
						external: true,
						id
					};
				}
				if (importer && isBareImport(id)) return resolved;
				return {
					external: true,
					...resolved,
					id: resolved?.id || id
				};
			}
		},
		load: { async handler(id) {
			if (id.startsWith(CJS_SHIM_PREFIX$1)) {
				const meta = shimMeta.get(id);
				if (!meta) return { code: `module.exports = require('${id.slice(10)}');` };
				const { pkgDir, pkgName } = meta;
				if (pkgDir) return { code: `
import { createRequire } from 'node:module';
import { fileURLToPath } from 'node:url';
import { dirname, join } from 'node:path';

const requireFromContext = createRequire(join(dirname(fileURLToPath(import.meta.url)), '${join$1("..", pkgDir, "package.json")}'));
module.exports = requireFromContext('${pkgName}');
`.trim() };
				return { code: `module.exports = require('${pkgName}');` };
			}
			return null;
		} }
	};
};

//#endregion
//#region src/cervel/node-file-trace.ts
const nodeFileTrace = async (args) => {
	const { span } = args;
	const files = {};
	const { tracedPaths } = args;
	const compiledSourceFiles = await glob("**/*", {
		cwd: args.outDir,
		follow: true,
		includeDirectories: true
	});
	for (const file of Object.keys(compiledSourceFiles)) files[file] = compiledSourceFiles[file];
	/**
	* While we're not using NFT to process source code, we are using it
	* to tree shake node deps, and include any fs reads for files that are
	* not part of the traced paths or compiled source files.
	* Most of this is identical to the `@vercel/node` implementation
	*/
	const runNft = () => nodeFileTrace$1(Array.from(tracedPaths), {
		base: args.repoRootPath,
		processCwd: args.workPath,
		ts: true,
		mixedModules: true,
		async resolve(id, parent, job, cjsResolve) {
			return resolve(id, parent, job, cjsResolve);
		},
		async readFile(fsPath) {
			try {
				let source = await readFile(fsPath);
				if (fsPath.endsWith(".ts") && !fsPath.endsWith(".d.ts") || fsPath.endsWith(".tsx") || fsPath.endsWith(".mts") || fsPath.endsWith(".cts")) source = (await transform(fsPath, source.toString())).code;
				return source;
			} catch (error) {
				if (isNativeError(error) && "code" in error && (error.code === "ENOENT" || error.code === "EISDIR")) return null;
				throw error;
			}
		}
	});
	const result = await span.child("vc.builder.backends.nft").trace(runNft);
	if (!args.keepTracedPaths) for (const file of tracedPaths) {
		const relativeFile = relative(args.repoRootPath, file);
		result.fileList.delete(relativeFile);
	}
	debug("NFT traced files count:", result.fileList.size);
	for (const file of result.fileList) {
		const absolutePath = join$1(args.repoRootPath, file);
		const stats = await lstat(absolutePath);
		const outputPath = file;
		if (stats.isSymbolicLink() || stats.isFile()) files[outputPath] = new FileFsRef({
			fsPath: absolutePath,
			mode: stats.mode
		});
	}
	debug("Total files in context:", Object.keys(files).length);
	return files;
};

//#endregion
//#region src/cervel/rolldown.ts
const __dirname__filenameShim = `
import { createRequire as __createRequire } from 'node:module';
import { fileURLToPath as __fileURLToPath } from 'node:url';
import { dirname as __dirname_ } from 'node:path';
var require = typeof require !== 'undefined' ? require : __createRequire(import.meta.url);
var __filename = typeof __filename !== 'undefined' ? __filename : __fileURLToPath(import.meta.url);
var __dirname = typeof __dirname !== 'undefined' ? __dirname : __dirname_(__filename);
`.trim();
const rolldown$1 = async (args) => {
	const entrypointPath = join$1(args.workPath, args.entrypoint);
	const outputDir = join$1(args.workPath, args.out);
	const extension = extname$1(args.entrypoint);
	const extensionMap = {
		".ts": {
			format: "auto",
			extension: "js"
		},
		".mts": {
			format: "esm",
			extension: "mjs"
		},
		".cts": {
			format: "cjs",
			extension: "cjs"
		},
		".cjs": {
			format: "cjs",
			extension: "cjs"
		},
		".js": {
			format: "auto",
			extension: "js"
		},
		".mjs": {
			format: "esm",
			extension: "mjs"
		}
	};
	const extensionInfo = extensionMap[extension] || extensionMap[".js"];
	let resolvedFormat = extensionInfo.format === "auto" ? void 0 : extensionInfo.format;
	const packageJsonPath = join$1(args.workPath, "package.json");
	const external = [];
	let pkg = {};
	if (existsSync(packageJsonPath)) {
		const source = await readFile(packageJsonPath, "utf8");
		try {
			pkg = JSON.parse(source.toString());
		} catch (_e) {
			pkg = {};
		}
		if (extensionInfo.format === "auto") if (pkg.type === "module") resolvedFormat = "esm";
		else resolvedFormat = "cjs";
		for (const dependency of Object.keys(pkg.dependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.devDependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.peerDependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.optionalDependencies || {})) external.push(dependency);
	}
	const resolvedExtension = resolvedFormat === "esm" ? "mjs" : "cjs";
	const context = { tracedPaths: /* @__PURE__ */ new Set() };
	const runRolldown = () => build$2({
		input: entrypointPath,
		cwd: args.workPath,
		platform: "node",
		tsconfig: true,
		plugins: [plugin({
			repoRootPath: args.repoRootPath,
			outDir: outputDir,
			workPath: args.workPath,
			shimBareImports: resolvedFormat === "esm",
			context
		})],
		output: {
			cleanDir: true,
			dir: outputDir,
			format: resolvedFormat,
			entryFileNames: `[name].${resolvedExtension}`,
			preserveModules: true,
			preserveModulesRoot: args.repoRootPath,
			sourcemap: false,
			banner: resolvedFormat === "esm" ? __dirname__filenameShim : void 0
		}
	});
	const out = await args.span.child("vc.builder.backends.rolldown").trace(runRolldown);
	let handler = null;
	for (const entry of out.output) if (entry.type === "chunk") {
		if (entry.isEntry) handler = entry.fileName;
	}
	if (typeof handler !== "string") throw new Error(`Unable to resolve module for ${args.entrypoint}`);
	const outputFiles = await nodeFileTrace({
		outDir: outputDir,
		tracedPaths: Array.from(context.tracedPaths),
		repoRootPath: args.repoRootPath,
		workPath: args.workPath,
		keepTracedPaths: false,
		span: args.span
	});
	const cleanup = async () => {
		await rm(outputDir, {
			recursive: true,
			force: true
		});
	};
	return {
		result: {
			handler,
			outputDir,
			outputFiles
		},
		cleanup
	};
};

//#endregion
//#region src/cervel/utils.ts
const noColor = globalThis.process?.env?.NO_COLOR === "1" || globalThis.process?.env?.TERM === "dumb";
const resets = {
	1: 22,
	31: 39,
	32: 39,
	33: 39,
	34: 39,
	35: 39,
	36: 39,
	90: 39
};
const _c = (c) => (text) => {
	if (noColor) return text;
	return `\u001B[${c}m${text}\u001B[${resets[c] ?? 0}m`;
};
const Colors = {
	bold: _c(1),
	red: _c(31),
	green: _c(32),
	yellow: _c(33),
	blue: _c(34),
	magenta: _c(35),
	cyan: _c(36),
	gray: _c(90),
	url: (title, url) => noColor ? `[${title}](${url})` : `\u001B]8;;${url}\u001B\\${title}\u001B]8;;\u001B\\`
};

//#endregion
//#region src/cervel/typescript.ts
const require_$1 = createRequire$1(import.meta.url);
const typescript$1 = (args) => {
	const { span } = args;
	return span.child("vc.builder.backends.tsCompile").trace(async () => {
		const extension = extname(args.entrypoint);
		if (![
			".ts",
			".mts",
			".cts"
		].includes(extension)) return;
		const tscPath = resolveTscPath$1(args);
		if (!tscPath) {
			console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck skipped ${Colors.gray("(TypeScript not found)")}`));
			return null;
		}
		return doTypeCheck$1(args, tscPath);
	});
};
async function doTypeCheck$1(args, tscPath) {
	let stdout = "";
	let stderr = "";
	/**
	* This might be subject to change.
	* - if no tscPath, skip typecheck
	* - if tsconfig, provide the tsconfig path
	* - else provide the entrypoint path
	*/
	const tscArgs = [
		tscPath,
		"--noEmit",
		"--pretty",
		"--allowJs",
		"--esModuleInterop",
		"--skipLibCheck"
	];
	const tsconfig = await findNearestTsconfig$1(args.workPath);
	if (tsconfig) tscArgs.push("--project", tsconfig);
	else tscArgs.push(args.entrypoint);
	const child = spawn(process.execPath, tscArgs, {
		cwd: args.workPath,
		stdio: [
			"ignore",
			"pipe",
			"pipe"
		]
	});
	child.stdout?.on("data", (data) => {
		stdout += data.toString();
	});
	child.stderr?.on("data", (data) => {
		stderr += data.toString();
	});
	await new Promise((resolve$1, reject) => {
		child.on("close", (code) => {
			if (code === 0) {
				console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck complete`));
				resolve$1();
			} else {
				const output = stdout || stderr;
				if (output) {
					console.error("\nTypeScript type check failed:\n");
					console.error(output);
				}
				reject(/* @__PURE__ */ new Error("TypeScript type check failed"));
			}
		});
		child.on("error", (err) => {
			reject(err);
		});
	});
}
const resolveTscPath$1 = (args) => {
	try {
		return require_$1.resolve("typescript/bin/tsc", { paths: [args.workPath] });
	} catch (e) {
		return null;
	}
};
const findNearestTsconfig$1 = async (workPath) => {
	const tsconfigPath = join(workPath, "tsconfig.json");
	if (existsSync$1(tsconfigPath)) return tsconfigPath;
	if (workPath === "/") return;
	return findNearestTsconfig$1(join(workPath, ".."));
};

//#endregion
//#region src/find-entrypoint.ts
const frameworks = [
	"express",
	"hono",
	"elysia",
	"fastify",
	"@nestjs/core",
	"h3"
];
const entrypointFilenames = [
	"app",
	"index",
	"server",
	"main",
	"src/app",
	"src/index",
	"src/server",
	"src/main"
];
const entrypointExtensions = [
	"js",
	"cjs",
	"mjs",
	"ts",
	"cts",
	"mts"
];
const entrypoints = entrypointFilenames.flatMap((filename) => entrypointExtensions.map((extension) => `${filename}.${extension}`));
const createFrameworkRegex = (framework) => new RegExp(`(?:from|require|import)\\s*(?:\\(\\s*)?["']${framework}["']\\s*(?:\\))?`, "g");
const findEntrypoint = async (cwd) => {
	let framework;
	try {
		const packageJson = await readFile(join$1(cwd, "package.json"), "utf-8");
		const packageJsonObject = JSON.parse(packageJson);
		framework = frameworks.find((framework$1) => packageJsonObject.dependencies?.[framework$1]);
	} catch (_) {}
	if (!framework) for (const entrypoint of entrypoints) {
		const entrypointPath = join$1(cwd, entrypoint);
		try {
			await readFile(entrypointPath, "utf-8");
			return entrypoint;
		} catch (_) {}
	}
	const regex = framework ? createFrameworkRegex(framework) : void 0;
	for (const entrypoint of entrypoints) {
		const entrypointPath = join$1(cwd, entrypoint);
		try {
			const content = await readFile(entrypointPath, "utf-8");
			if (regex) {
				if (regex.test(content)) return entrypoint;
			}
		} catch (_) {}
	}
};
const findEntrypointOrThrow = async (cwd) => {
	const entrypoint = await findEntrypoint(cwd);
	if (!entrypoint) throw new Error(`No entrypoint found in "${cwd}". Expected one of: ${entrypoints.join(", ")}`);
	return entrypoint;
};

//#endregion
//#region src/cervel/index.ts
const require$2 = createRequire(import.meta.url);
const getBuildSummary = async (outputDir) => {
	const buildSummary = await readFile$1(join$1(outputDir, ".cervel.json"), "utf-8");
	return JSON.parse(buildSummary);
};
const build$1 = async (args) => {
	const entrypoint = args.entrypoint || await findEntrypointOrThrow(args.workPath);
	const span = args.span ?? new Span({ name: "cervel-build" });
	const [, rolldownResult] = await Promise.all([typescript$1({
		entrypoint,
		workPath: args.workPath,
		span
	}), rolldown$1({
		entrypoint,
		workPath: args.workPath,
		repoRootPath: args.repoRootPath,
		out: args.out,
		span
	})]);
	await writeFile(join$1(args.workPath, args.out, ".cervel.json"), JSON.stringify({ handler: rolldownResult.result.handler }, null, 2));
	console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Build complete`));
	return { rolldownResult: rolldownResult.result };
};
const serve = async (args) => {
	const entrypoint = await findEntrypointOrThrow(args.workPath);
	const srvxBin = join$1(require$2.resolve("srvx"), "..", "..", "..", "bin", "srvx.mjs");
	const tsxBin = require$2.resolve("tsx");
	const restArgs = Object.entries(args.rest).filter(([, value]) => value !== void 0 && value !== false).map(([key, value]) => typeof value === "boolean" ? `--${key}` : `--${key}=${value}`);
	if (!args.rest.import) restArgs.push("--import", tsxBin);
	await execa("npx", [
		srvxBin,
		...restArgs,
		entrypoint
	], {
		cwd: args.workPath,
		stdio: "inherit"
	});
};
const srvxOptions = {
	help: {
		type: "boolean",
		short: "h"
	},
	version: {
		type: "boolean",
		short: "v"
	},
	prod: { type: "boolean" },
	port: {
		type: "string",
		short: "p"
	},
	host: {
		type: "string",
		short: "H"
	},
	static: {
		type: "string",
		short: "s"
	},
	import: { type: "string" },
	tls: { type: "boolean" },
	cert: { type: "string" },
	key: { type: "string" }
};

//#endregion
//#region src/rolldown/resolve-format.ts
const resolveEntrypointAndFormat = async (args) => {
	const extension = extname$1(args.entrypoint);
	const extensionMap = {
		".ts": {
			format: "auto",
			extension: "js"
		},
		".mts": {
			format: "esm",
			extension: "mjs"
		},
		".cts": {
			format: "cjs",
			extension: "cjs"
		},
		".cjs": {
			format: "cjs",
			extension: "cjs"
		},
		".js": {
			format: "auto",
			extension: "js"
		},
		".mjs": {
			format: "esm",
			extension: "mjs"
		}
	};
	const extensionInfo = extensionMap[extension] || extensionMap[".js"];
	let resolvedFormat = extensionInfo.format === "auto" ? void 0 : extensionInfo.format;
	const packageJsonPath = join$1(args.workPath, "package.json");
	let pkg = {};
	if (existsSync(packageJsonPath)) {
		const source = await readFile(packageJsonPath, "utf8");
		try {
			pkg = JSON.parse(source.toString());
		} catch (_e) {
			pkg = {};
		}
		if (extensionInfo.format === "auto") if (pkg.type === "module") resolvedFormat = "esm";
		else resolvedFormat = "cjs";
	}
	if (!resolvedFormat) throw new Error(`Unable to resolve format for ${args.entrypoint}`);
	return {
		format: resolvedFormat,
		extension: resolvedFormat === "esm" ? "mjs" : "cjs"
	};
};

//#endregion
//#region src/rolldown/nft.ts
const nft = async (args) => {
	const nftSpan = args.span.child("vc.builder.backends.nft");
	const runNft = async () => {
		const ignorePatterns = [...args.ignoreNodeModules ? ["**/node_modules/**"] : [], ...args.ignore ? Array.isArray(args.ignore) ? args.ignore : [args.ignore] : []];
		const nftResult = await nodeFileTrace$1(Array.from(args.localBuildFiles), {
			base: args.repoRootPath,
			processCwd: args.workPath,
			ts: true,
			mixedModules: true,
			conditions: args.conditions,
			ignore: ignorePatterns.length > 0 ? ignorePatterns : void 0,
			async readFile(fsPath) {
				try {
					let source = await readFile(fsPath);
					if (isTypeScriptFile(fsPath)) source = (await transform(fsPath, source.toString())).code;
					return source;
				} catch (error) {
					if (isNativeError(error) && "code" in error && (error.code === "ENOENT" || error.code === "EISDIR")) return null;
					throw error;
				}
			}
		});
		for (const file of nftResult.fileList) {
			const absolutePath = join$1(args.repoRootPath, file);
			const stats = await lstat(absolutePath);
			const outputPath = file;
			if (args.localBuildFiles.has(join$1(args.repoRootPath, outputPath))) continue;
			if (stats.isSymbolicLink() || stats.isFile()) if (args.ignoreNodeModules) {
				if ((stats.isSymbolicLink() ? await stat(absolutePath) : stats).isFile()) {
					const content = await readFile(absolutePath, "utf-8");
					args.files[outputPath] = new FileBlob({
						data: content,
						mode: stats.mode
					});
				}
			} else args.files[outputPath] = new FileFsRef({
				fsPath: absolutePath,
				mode: stats.mode
			});
		}
	};
	await nftSpan.trace(runNft);
};
const isTypeScriptFile = (fsPath) => {
	return fsPath.endsWith(".ts") || fsPath.endsWith(".tsx") || fsPath.endsWith(".mts") || fsPath.endsWith(".cts");
};

//#endregion
//#region src/rolldown/index.ts
const PLUGIN_NAME = "vercel:backends";
const CJS_SHIM_PREFIX = "\0cjs-shim:";
const rolldown = async (args) => {
	const files = {};
	const { format, extension } = await resolveEntrypointAndFormat(args);
	const localBuildFiles = /* @__PURE__ */ new Set();
	let handler = null;
	const packageJsonCache = /* @__PURE__ */ new Map();
	const shimMeta = /* @__PURE__ */ new Map();
	const framework = {
		slug: "",
		version: ""
	};
	const getPackageJson = async (pkgPath) => {
		if (packageJsonCache.has(pkgPath)) return packageJsonCache.get(pkgPath);
		try {
			const contents = await readFile(pkgPath, "utf-8");
			const parsed = JSON.parse(contents);
			packageJsonCache.set(pkgPath, parsed);
			return parsed;
		} catch {
			packageJsonCache.set(pkgPath, null);
			return null;
		}
	};
	const isCommonJS = async (bareImport, resolvedPath, resolvedInfo) => {
		const ext = extname$1(resolvedPath);
		if (ext === ".cjs") return true;
		if (ext === ".mjs") return false;
		if (ext === ".js" || ext === ".ts") {
			const pkgJsonPath = resolvedInfo.packageJsonPath;
			if (!pkgJsonPath) return true;
			const pkgJson = await getPackageJson(pkgJsonPath);
			if (!pkgJson) return true;
			const pkgDir = dirname$1(pkgJsonPath);
			const relativePath = resolvedPath.slice(pkgDir.length + 1).replace(/\\/g, "/");
			const pkgName = pkgJson.name || "";
			const subpath = bareImport.startsWith(pkgName) ? `.${bareImport.slice(pkgName.length)}` || "." : ".";
			try {
				if (exports(pkgJson, subpath, {
					require: false,
					conditions: ["node", "import"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return false;
				if (exports(pkgJson, subpath, {
					require: true,
					conditions: ["node", "require"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return true;
			} catch {}
			if (pkgJson.module) return false;
			return pkgJson.type !== "module";
		}
		return true;
	};
	const isBareImport = (id) => {
		return !id.startsWith(".") && !id.startsWith("/") && !/^[a-z][a-z0-9+.-]*:/i.test(id);
	};
	const isNodeModule = (resolved) => {
		return resolved?.id?.includes("node_modules") ?? false;
	};
	const isNodeBuiltin = (id) => {
		const normalizedId = id.includes(":") ? id.split(":")[1] : id;
		return builtinModules.includes(normalizedId);
	};
	const isBunBuiltin = (id) => {
		return id === "bun" || id.startsWith("bun:");
	};
	const isLocalImport = (id) => {
		return !id.startsWith("node:") && !id.includes("node_modules");
	};
	const plugin$1 = () => {
		return {
			name: PLUGIN_NAME,
			resolveId: {
				order: "pre",
				async handler(id, importer, rOpts) {
					if (id.startsWith(CJS_SHIM_PREFIX)) return {
						id,
						external: false
					};
					const resolved = await this.resolve(id, importer, rOpts);
					if (isNodeBuiltin(id)) return {
						id: id.startsWith("node:") ? id : `node:${id}`,
						external: true
					};
					if (isBunBuiltin(id)) return {
						id,
						external: true
					};
					if (resolved?.id && isLocalImport(resolved.id)) localBuildFiles.add(resolved.id);
					else if (!resolved) localBuildFiles.add(join$1(args.workPath, id));
					if (importer?.startsWith(CJS_SHIM_PREFIX) && isBareImport(id)) return {
						id,
						external: true
					};
					if (importer && isBareImport(id) && isNodeModule(resolved)) {
						if (isBackendFramework(id) && resolved?.packageJsonPath) try {
							const pkg = await readFile(resolved.packageJsonPath, "utf8");
							const pkgJson = JSON.parse(pkg);
							framework.slug = pkgJson.name;
							framework.version = pkgJson.version;
						} catch {}
						if (resolved ? await isCommonJS(id, resolved.id, resolved) : false) {
							const importerPkgJsonPath = (await this.resolve(importer))?.packageJsonPath;
							if (importerPkgJsonPath) {
								const importerPkgDir = relative(args.repoRootPath, dirname$1(importerPkgJsonPath));
								const shimId$1 = `${CJS_SHIM_PREFIX}${importerPkgDir.replace(/\//g, "_")}_${id.replace(/\//g, "_")}`;
								shimMeta.set(shimId$1, {
									pkgDir: importerPkgDir,
									pkgName: id
								});
								return {
									id: shimId$1,
									external: false
								};
							}
							const shimId = `${CJS_SHIM_PREFIX}${id.replace(/\//g, "_")}`;
							shimMeta.set(shimId, {
								pkgDir: "",
								pkgName: id
							});
							return {
								id: shimId,
								external: false
							};
						}
						return {
							id,
							external: true
						};
					}
					if (importer && isBareImport(id)) return resolved;
					if (resolved && !isNodeModule(resolved)) return resolved;
					return resolved;
				}
			},
			load: { async handler(id) {
				if (id.startsWith(CJS_SHIM_PREFIX)) {
					const meta = shimMeta.get(id);
					if (!meta) return { code: `module.exports = require('${id.slice(10)}');` };
					const { pkgDir, pkgName } = meta;
					return { code: `
import { createRequire } from 'node:module';
import { fileURLToPath } from 'node:url';
import { dirname, join } from 'node:path';

const requireFromContext = createRequire(join(dirname(fileURLToPath(import.meta.url)), '${pkgDir ? join$1("..", pkgDir, "package.json") : "../package.json"}'));
module.exports = requireFromContext('${pkgName}');
`.trim() };
				}
				return null;
			} }
		};
	};
	const runRolldown = () => build$2({
		input: args.entrypoint,
		write: false,
		cwd: args.workPath,
		platform: "node",
		transform: { define: format === "esm" ? {
			__dirname: "import.meta.dirname",
			__filename: "import.meta.filename"
		} : void 0 },
		tsconfig: true,
		plugins: [plugin$1()],
		output: {
			cleanDir: true,
			format,
			entryFileNames: `[name].${extension}`,
			preserveModules: true,
			preserveModulesRoot: args.repoRootPath,
			sourcemap: false
		}
	});
	const rolldownSpan = args.span?.child("vc.builder.backends.rolldown");
	const out = await rolldownSpan?.trace(runRolldown) || await runRolldown();
	for (const file of out.output) if (file.type === "chunk") {
		if (file.isEntry) handler = file.fileName;
		files[file.fileName] = new FileBlob({
			data: file.code,
			mode: 420
		});
	}
	await nft({
		...args,
		localBuildFiles,
		files,
		span: rolldownSpan ?? new Span({ name: "vc.builder.backends.nft" }),
		ignoreNodeModules: true,
		ignore: args.config.excludeFiles
	});
	if (!handler) throw new Error(`Unable to resolve build handler for entrypoint: ${args.entrypoint}`);
	console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Build complete`));
	return {
		files,
		handler,
		framework,
		localBuildFiles
	};
};

//#endregion
//#region src/rolldown/util.ts
const BEGIN_INTROSPECTION_RESULT = "\n__VERCEL_INTROSPECTION_BEGIN__\n";
const END_INTROSPECTION_RESULT = "\n__VERCEL_INTROSPECTION_END__\n";

//#endregion
//#region src/rolldown/introspection.ts
const require$1 = createRequire(import.meta.url);
const introspectionSchema = z.object({
	routes: z.array(z.object({
		src: z.string(),
		dest: z.string(),
		methods: z.array(z.string())
	})),
	additionalFolders: z.array(z.string()).optional(),
	additionalDeps: z.array(z.string()).optional()
});
const introspection = async (args) => {
	const defaultResult$1 = {
		routes: [],
		additionalFolders: [],
		additionalDeps: []
	};
	if (isExperimentalBackendsWithoutIntrospectionEnabled()) return defaultResult$1;
	const introspectionSpan = args.span.child("vc.builder.backends.introspection");
	const runIntrospection = async () => {
		const rolldownEsmLoaderPath = `file://${require$1.resolve("@vercel/backends/rolldown/esm")}`;
		const rolldownCjsLoaderPath = require$1.resolve("@vercel/backends/rolldown/cjs-hooks");
		const handlerPath = join$1(args.workPath, args.entrypoint);
		const files = args.files;
		const tmpDir = mkdtempSync(join$1(tmpdir(), "vercel-introspection-"));
		for (const [key, value] of Object.entries(files)) {
			if (!(value instanceof FileBlob) || typeof value.data !== "string") continue;
			const filePath = join$1(tmpDir, key);
			mkdirSync(dirname$1(filePath), { recursive: true });
			writeFileSync(filePath, value.data);
		}
		let introspectionData;
		await new Promise((resolvePromise) => {
			try {
				debug("Spawning introspection process");
				const outputTempDir = mkdtempSync(join$1(tmpdir(), "introspection-output-"));
				const tempFilePath = join$1(outputTempDir, "output.txt");
				const writeStream = createWriteStream(tempFilePath);
				let streamClosed = false;
				const child = spawn$1("node", [
					"-r",
					rolldownCjsLoaderPath,
					"--import",
					rolldownEsmLoaderPath,
					handlerPath
				], {
					stdio: [
						"pipe",
						"pipe",
						"pipe"
					],
					cwd: args.workPath,
					env: {
						...process.env,
						...args.meta?.buildEnv,
						...args.meta?.env,
						VERCEL_INTROSPECTION_HANDLER: handlerPath,
						VERCEL_INTROSPECTION_HANDLER_BUILT: args.handler,
						VERCEL_INTROSPECTION_WORK_PATH: args.workPath,
						VERCEL_INTROSPECTION_REPO_ROOT_PATH: args.repoRootPath,
						VERCEL_INTROSPECTION_TMP_DIR: tmpDir
					}
				});
				child.stdout?.pipe(writeStream);
				let stderrBuffer = "";
				child.stderr?.on("data", (data) => {
					stderrBuffer += data.toString();
				});
				writeStream.on("error", (err) => {
					debug(`Write stream error: ${err.message}`);
				});
				const timeout = setTimeout(() => {
					debug("Introspection timeout, killing process with SIGTERM");
					child.kill("SIGTERM");
				}, 8e3);
				const timeout2 = setTimeout(() => {
					debug("Introspection timeout, killing process with SIGKILL");
					child.kill("SIGKILL");
				}, 9e3);
				const cleanup = () => {
					clearTimeout(timeout);
					clearTimeout(timeout2);
					try {
						rmSync(tmpDir, {
							recursive: true,
							force: true
						});
					} catch (err) {
						debug(`Error deleting tmpDir: ${err}`);
					}
				};
				child.on("error", (err) => {
					cleanup();
					debug(`Loader error: ${err.message}`);
					if (!streamClosed) writeStream.end(() => {
						streamClosed = true;
						try {
							rmSync(outputTempDir, {
								recursive: true,
								force: true
							});
						} catch (cleanupErr) {
							debug(`Error deleting output temp dir: ${cleanupErr}`);
						}
						resolvePromise();
					});
					else resolvePromise();
				});
				child.on("close", () => {
					cleanup();
					debug("Introspection process closed");
					if (!streamClosed) writeStream.end(() => {
						streamClosed = true;
						let stdoutBuffer;
						try {
							stdoutBuffer = readFileSync(tempFilePath, "utf8");
							const beginIndex = stdoutBuffer.indexOf(BEGIN_INTROSPECTION_RESULT);
							const endIndex = stdoutBuffer.indexOf(END_INTROSPECTION_RESULT);
							if (beginIndex !== -1 && endIndex !== -1) {
								const introspectionString = stdoutBuffer.substring(beginIndex + BEGIN_INTROSPECTION_RESULT.length, endIndex);
								if (introspectionString) {
									introspectionData = introspectionSchema.parse(JSON.parse(introspectionString));
									debug("Introspection data parsed successfully");
								}
							} else debug(`Introspection markers not found.\nstdout:\n${stdoutBuffer}\nstderr:\n${stderrBuffer}`);
						} catch (error) {
							debug(`Error parsing introspection data: ${error}\nstdout:\n${stdoutBuffer}\nstderr:\n${stderrBuffer}`);
						} finally {
							try {
								rmSync(outputTempDir, {
									recursive: true,
									force: true
								});
							} catch (err) {
								debug(`Error deleting output temp directory: ${err}`);
							}
							resolvePromise();
						}
					});
					else resolvePromise();
				});
			} catch (error) {
				debug("Introspection error", error);
				resolvePromise();
			}
		});
		if (!introspectionData) {
			introspectionSpan.setAttributes({
				"introspection.success": "false",
				"introspection.routes": "0"
			});
			return defaultResult$1;
		}
		const additionalFolders = (introspectionData.additionalFolders ?? []).map((val) => {
			if (isAbsolute(val)) return relative(args.workPath, val);
			return val;
		});
		introspectionSpan.setAttributes({
			"introspection.success": "true",
			"introspection.routes": String(introspectionData.routes.length)
		});
		return {
			routes: introspectionData.routes,
			additionalFolders,
			additionalDeps: introspectionData.additionalDeps ?? []
		};
	};
	return introspectionSpan.trace(runIntrospection);
};

//#endregion
//#region src/build.ts
const maybeDoBuildCommand = async (args, downloadResult) => {
	const buildCommandResult = await maybeExecBuildCommand(args, downloadResult);
	const outputSetting = args.config.outputDirectory;
	let outputDir;
	let entrypoint;
	if (buildCommandResult && outputSetting) if (outputSetting) {
		const _outputDir = join$1(args.workPath, outputSetting);
		const _entrypoint = await findEntrypoint(_outputDir);
		if (_entrypoint) {
			outputDir = _outputDir;
			entrypoint = _entrypoint;
		}
	} else for (const outputDirectory of [
		"dist",
		"build",
		"output"
	]) {
		const _outputDir = join$1(args.workPath, outputDirectory);
		if (existsSync(_outputDir)) {
			const _entrypoint = await findEntrypoint(_outputDir);
			if (_entrypoint) {
				outputDir = _outputDir;
				entrypoint = _entrypoint;
				break;
			}
		}
	}
	const localBuildFiles = /* @__PURE__ */ new Set();
	let files;
	if (outputDir && entrypoint) {
		files = await glob("**", outputDir);
		for (const file of Object.keys(files)) localBuildFiles.add(join$1(outputDir, file));
	}
	return {
		localBuildFiles,
		files,
		handler: entrypoint,
		outputDir
	};
};

//#endregion
//#region src/typescript.ts
const require_ = createRequire(import.meta.url);
const typescript = (args) => {
	const { span } = args;
	return span.child("vc.builder.backends.tsCompile").trace(async () => {
		const extension = extname$1(args.entrypoint);
		if (![
			".ts",
			".mts",
			".cts"
		].includes(extension)) return;
		const tscPath = resolveTscPath(args);
		if (!tscPath) {
			console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck skipped ${Colors.gray("(TypeScript not found)")}`));
			return null;
		}
		return doTypeCheck(args, tscPath);
	});
};
async function doTypeCheck(args, tscPath) {
	let stdout = "";
	let stderr = "";
	/**
	* This might be subject to change.
	* - if no tscPath, skip typecheck
	* - if tsconfig, provide the tsconfig path
	* - else provide the entrypoint path
	*/
	const tscArgs = [
		tscPath,
		"--noEmit",
		"--pretty",
		"--allowJs",
		"--esModuleInterop",
		"--skipLibCheck"
	];
	const tsconfig = await findNearestTsconfig(args.workPath);
	if (tsconfig) tscArgs.push("--project", tsconfig);
	else tscArgs.push(args.entrypoint);
	const child = spawn$1(process.execPath, tscArgs, {
		cwd: args.workPath,
		stdio: [
			"ignore",
			"pipe",
			"pipe"
		]
	});
	child.stdout?.on("data", (data) => {
		stdout += data.toString();
	});
	child.stderr?.on("data", (data) => {
		stderr += data.toString();
	});
	await new Promise((resolve$1, reject) => {
		child.on("close", (code) => {
			if (code === 0) {
				console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck complete`));
				resolve$1();
			} else {
				const output = stdout || stderr;
				if (output) {
					console.error("\nTypeScript type check failed:\n");
					console.error(output);
				}
				reject(/* @__PURE__ */ new Error("TypeScript type check failed"));
			}
		});
		child.on("error", (err) => {
			reject(err);
		});
	});
}
const resolveTscPath = (args) => {
	try {
		return require_.resolve("typescript/bin/tsc", { paths: [args.workPath] });
	} catch (e) {
		return null;
	}
};
const findNearestTsconfig = async (workPath) => {
	const tsconfigPath = join$1(workPath, "tsconfig.json");
	if (existsSync(tsconfigPath)) return tsconfigPath;
	if (workPath === "/") return;
	return findNearestTsconfig(join$1(workPath, ".."));
};

//#endregion
//#region src/introspection/index.ts
const require = createRequire(import.meta.url);
const introspectApp = async (args) => {
	const { span } = args;
	const introspectionSpan = span.child("vc.builder.backends.introspection");
	if (isExperimentalBackendsWithoutIntrospectionEnabled()) return defaultResult(args);
	const cjsLoaderPath = require.resolve("@vercel/backends/introspection/loaders/cjs");
	const rolldownEsmLoaderPath = `file://${require.resolve("@vercel/backends/introspection/loaders/rolldown-esm")}`;
	const handlerPath = join$1(args.dir, args.handler);
	const introspectionSchema$1 = z.object({
		frameworkSlug: z.string().optional(),
		routes: z.array(z.object({
			src: z.string(),
			dest: z.string(),
			methods: z.array(z.string())
		})),
		additionalFolders: z.array(z.string()).optional().transform((values) => {
			return values?.map((val) => {
				if (isAbsolute(val)) return relative(args.dir, val);
				return val;
			});
		}),
		additionalDeps: z.array(z.string()).optional()
	});
	let introspectionData;
	await new Promise((resolvePromise) => {
		try {
			debug("Spawning introspection process");
			const child = spawn$1("node", [
				"-r",
				cjsLoaderPath,
				"--import",
				rolldownEsmLoaderPath,
				handlerPath
			], {
				stdio: [
					"pipe",
					"pipe",
					"pipe"
				],
				cwd: args.dir,
				env: {
					...process.env,
					...args.env
				}
			});
			const tempDir = mkdtempSync(join$1(tmpdir(), "introspection-"));
			const tempFilePath = join$1(tempDir, "output.txt");
			const writeStream = createWriteStream(tempFilePath);
			let streamClosed = false;
			child.stdout?.pipe(writeStream);
			let stderrBuffer = "";
			child.stderr?.on("data", (data) => {
				stderrBuffer += data.toString();
			});
			writeStream.on("error", (err) => {
				debug(`Write stream error: ${err.message}`);
			});
			const timeout = setTimeout(() => {
				debug("Introspection timeout, killing process with SIGTERM");
				child.kill("SIGTERM");
			}, 8e3);
			const timeout2 = setTimeout(() => {
				debug("Introspection timeout, killing process with SIGKILL");
				child.kill("SIGKILL");
			}, 9e3);
			child.on("error", (err) => {
				clearTimeout(timeout);
				clearTimeout(timeout2);
				debug(`Loader error: ${err.message}`);
				if (!streamClosed) writeStream.end(() => {
					streamClosed = true;
					try {
						unlinkSync(tempFilePath);
					} catch (cleanupErr) {
						debug(`Error deleting temp file on error: ${cleanupErr}`);
					}
					resolvePromise(void 0);
				});
				else resolvePromise(void 0);
			});
			child.on("close", () => {
				clearTimeout(timeout);
				clearTimeout(timeout2);
				debug("Introspection process closed");
				if (!streamClosed) writeStream.end(() => {
					streamClosed = true;
					let stdoutBuffer;
					try {
						stdoutBuffer = readFileSync(tempFilePath, "utf8");
						const beginIndex = stdoutBuffer.indexOf(BEGIN_INTROSPECTION_RESULT);
						const endIndex = stdoutBuffer.indexOf(END_INTROSPECTION_RESULT);
						if (beginIndex !== -1 && endIndex !== -1) {
							const introspectionString = stdoutBuffer.substring(beginIndex + BEGIN_INTROSPECTION_RESULT.length, endIndex);
							if (introspectionString) {
								introspectionData = introspectionSchema$1.parse(JSON.parse(introspectionString));
								debug("Introspection data parsed successfully");
							}
						} else debug(`Introspection markers not found.\nstdout:\n${stdoutBuffer}\nstderr:\n${stderrBuffer}`);
					} catch (error) {
						debug(`Error parsing introspection data: ${error}\nstdout:\n${stdoutBuffer}\nstderr:\n${stderrBuffer}`);
					} finally {
						try {
							rmSync(tempDir, {
								recursive: true,
								force: true
							});
						} catch (err) {
							debug(`Error deleting temp directory: ${err}`);
						}
						resolvePromise(void 0);
					}
				});
				else resolvePromise(void 0);
			});
		} catch (error) {
			debug("Introspection error", error);
			resolvePromise(void 0);
		}
	});
	const framework = getFramework(args);
	if (!introspectionData) {
		introspectionSpan.setAttributes({
			"introspection.success": "false",
			"introspection.routes": "0"
		});
		return defaultResult(args);
	}
	const routes = [
		{ handle: "filesystem" },
		...introspectionData.routes,
		{
			src: "/(.*)",
			dest: "/"
		}
	];
	introspectionSpan.setAttributes({
		"introspection.success": "true",
		"introspection.routes": String(introspectionData.routes.length),
		"introspection.framework": introspectionData.frameworkSlug ?? ""
	});
	return {
		routes,
		framework,
		additionalFolders: introspectionData.additionalFolders ?? [],
		additionalDeps: introspectionData.additionalDeps ?? []
	};
};
const defaultResult = (args) => {
	return {
		routes: [{ handle: "filesystem" }, {
			src: "/(.*)",
			dest: "/"
		}],
		framework: getFramework(args)
	};
};
const getFramework = (args) => {
	try {
		let version$1;
		if (args.framework) {
			const frameworkLibPath = require.resolve(`${args.framework}`, { paths: [args.dir] });
			const findNearestPackageJson = (dir) => {
				const packageJsonPath = join$1(dir, "package.json");
				if (existsSync(packageJsonPath)) return packageJsonPath;
				const parentDir = dirname$1(dir);
				if (parentDir === dir) return;
				return findNearestPackageJson(parentDir);
			};
			const nearestPackageJsonPath = findNearestPackageJson(frameworkLibPath);
			if (nearestPackageJsonPath) version$1 = require(nearestPackageJsonPath).version;
		}
		return {
			slug: args.framework ?? "",
			version: version$1 ?? ""
		};
	} catch (error) {
		debug(`Error getting framework for ${args.framework}. Setting framework version to empty string.`, error);
		return {
			slug: args.framework ?? "",
			version: ""
		};
	}
};

//#endregion
//#region src/index.ts
const version = 2;
const build = async (args) => {
	const downloadResult = await downloadInstallAndBundle(args);
	const nodeVersion = await getNodeVersion(args.workPath, void 0, args.config, args.meta);
	const isBun = isBunVersion(nodeVersion);
	const builderName = "@vercel/backends";
	const span = args.span ?? new Span({ name: builderName });
	span.setAttributes({ "builder.name": builderName });
	const buildSpan = span.child("vc.builder.backends.build");
	return buildSpan.trace(async () => {
		const entrypoint = await findEntrypointOrThrow(args.workPath);
		debug("Entrypoint", entrypoint);
		args.entrypoint = entrypoint;
		const userBuildResult = await maybeDoBuildCommand(args, downloadResult);
		const functionConfig = args.config.functions?.[entrypoint];
		if (functionConfig) {
			args.config.includeFiles = [...normalizeArray(args.config.includeFiles), ...normalizeArray(functionConfig.includeFiles)];
			args.config.excludeFiles = [...normalizeArray(args.config.excludeFiles), ...normalizeArray(functionConfig.excludeFiles)];
		}
		const rolldownResult = await rolldown({
			...args,
			span: buildSpan
		});
		const introspectionPromise = introspection({
			...args,
			span: buildSpan,
			files: rolldownResult.files,
			handler: rolldownResult.handler
		});
		const typescriptPromise = typescript({
			entrypoint,
			workPath: args.workPath,
			span: buildSpan
		});
		const localBuildFiles = userBuildResult?.localBuildFiles.size > 0 ? userBuildResult?.localBuildFiles : rolldownResult.localBuildFiles;
		const files = userBuildResult?.files || rolldownResult.files;
		const handler = userBuildResult?.handler || rolldownResult.handler;
		const nftWorkPath = userBuildResult?.outputDir || args.workPath;
		await nft({
			...args,
			workPath: nftWorkPath,
			localBuildFiles,
			files,
			ignoreNodeModules: false,
			ignore: args.config.excludeFiles,
			conditions: isBun ? ["bun"] : void 0,
			span: buildSpan
		});
		const baseDir = args.repoRootPath || args.workPath;
		const includeResults = await Promise.all(normalizeArray(args.config.includeFiles).map((pattern) => glob(pattern, baseDir)));
		for (const matched of includeResults) for (const [relPath, entry] of Object.entries(matched)) files[relPath] = entry;
		const introspectionResult = await introspectionPromise;
		await typescriptPromise;
		const lambda = new NodejsLambda({
			runtime: nodeVersion.runtime,
			handler,
			files,
			framework: rolldownResult.framework,
			shouldAddHelpers: false,
			shouldAddSourcemapSupport: true,
			awsLambdaHandler: "",
			shouldDisableAutomaticFetchInstrumentation: process.env.VERCEL_TRACING_DISABLE_AUTOMATIC_FETCH_INSTRUMENTATION === "1"
		});
		const routes = [
			{ handle: "filesystem" },
			...introspectionResult.routes,
			{
				src: "/(.*)",
				dest: "/"
			}
		];
		const output = { index: lambda };
		for (const route of routes) if (route.dest) {
			if (route.dest === "/") continue;
			output[route.dest] = lambda;
		}
		return {
			routes,
			output
		};
	});
};
const prepareCache = ({ repoRootPath, workPath }) => {
	return glob(defaultCachePathGlob, repoRootPath || workPath);
};
const normalizeArray = (value) => Array.isArray(value) ? value : value ? [value] : [];

//#endregion
export { build, build$1 as cervelBuild, serve as cervelServe, findEntrypoint, findEntrypointOrThrow, getBuildSummary, introspectApp, nodeFileTrace, prepareCache, srvxOptions, version };